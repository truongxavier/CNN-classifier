ğŸª„ DocuMancer
Description
DocuMancer est une solution MLOps complÃ¨te pour la classification automatique de documents utilisant des techniques avancÃ©es de deep learning. Le projet utilise le dataset RVL-CDIP contenant 400 000 images de documents rÃ©partis en 16 catÃ©gories diffÃ©rentes (lettres, factures, mÃ©mos, etc.).
.
â”œâ”€â”€ bentoml_service
â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”œâ”€â”€ security
â”‚Â Â  â”‚Â Â  â””â”€â”€ __pycache__
â”‚Â Â  â”œâ”€â”€ src
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ preprocessing
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ service
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ __pycache__
â”‚Â Â  â”‚Â Â  â””â”€â”€ utils
â”‚Â Â  â””â”€â”€ tests
â”‚Â Â      â””â”€â”€ __pycache__
â”œâ”€â”€ data_pipeline
â”‚Â Â  â”œâ”€â”€ evaluation_results
â”‚Â Â  â”œâ”€â”€ mlflow
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ mlartifacts
â”‚Â Â  â”‚Â Â  â””â”€â”€ src
â”‚Â Â  â”œâ”€â”€ src
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ evaluation
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ preprocessing
â”‚Â Â  â”‚Â Â  â””â”€â”€ training
â”‚Â Â  â””â”€â”€ tests
â”œâ”€â”€ kubernetes
â”‚Â Â  â”œâ”€â”€ base
â”‚Â Â  â”œâ”€â”€ monitoring
â”‚Â Â  â”œâ”€â”€ network
â”‚Â Â  â”œâ”€â”€ scaling
â”‚Â Â  â””â”€â”€ secrets
â”œâ”€â”€ monitoring
â”‚Â Â  â”œâ”€â”€ grafana
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dashboards
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ pdf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ plugins
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ grafana-lokiexplore-app
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ img
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ png
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ provisioning
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ alerting
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dashboards
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ datasources
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ plugins
â”‚Â Â  â”‚Â Â  â””â”€â”€ reports
â”‚Â Â  â”œâ”€â”€ monitoring
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nginx
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ default.conf
â”‚Â Â  â”‚Â Â  â””â”€â”€ reports
â”‚Â Â  â”œâ”€â”€ nginx
â”‚Â Â  â”œâ”€â”€ prometheus
â”‚Â Â  â”‚Â Â  â””â”€â”€ alert_rules
â”‚Â Â  â””â”€â”€ reports
â”‚Â Â      â”œâ”€â”€ drift_report_20241211-100537
â”‚Â Â      â”œâ”€â”€ drift_report_20241211-110017
â”‚Â Â      â”œâ”€â”€ drift_report_20241211-110416
â”‚Â Â      â””â”€â”€ drift_report_20241211-111001
â”œâ”€â”€ scripts
â””â”€â”€ streamlit
    â””â”€â”€ images

ğŸŒŸ FonctionnalitÃ©s

Classification automatique de documents via CNN
Interface utilisateur intuitive avec Streamlit
Pipeline MLOps complet avec monitoring
DÃ©tection de drift de donnÃ©es
API RESTful pour les prÃ©dictions
Visualisation des mÃ©triques en temps rÃ©el

ğŸ—ï¸ Architecture
streamlit/images/Architecture.jpg
L'architecture du projet s'appuie sur les composants suivants :

MLflow pour le tracking des expÃ©riences
BentoML pour le serving
Prometheus/Grafana pour le monitoring
FastAPI pour l'exposition des services
Streamlit pour l'interface utilisateur

ğŸš€ Installation
PrÃ©requis

Python 3.8+
Docker & Docker Compose
CUDA compatible GPU (recommandÃ©)

Installation des dÃ©pendances
bashCopy# Cloner le repository
git clone https://github.com/votre-username/documancer.git
cd documancer

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: .\venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
DÃ©marrage des services
bashCopy# Lancer les services avec Docker Compose
docker-compose up -d

# VÃ©rifier que tous les services sont up
docker-compose ps
ğŸ“Š Services ExposÃ©s
Les services sont accessibles sur :

Grafana : http://localhost:3100
Prometheus : http://localhost:9090
Metrics Exporter : http://localhost:8000
MLflow : http://localhost:8080/
Drift Monitoring : http://localhost:8088/

ğŸ’» Utilisation
Lancement de l'interface Streamlit
bashCopystreamlit run presentation.py
Faire une prÃ©diction via l'API
pythonCopyimport requests
import json

# GÃ©nÃ©rer un token
token_response = requests.post(
    "http://localhost:3000/generate_token",
    headers={"Content-Type": "application/json"},
    json={"username": "test_user"}
)
token = token_response.json()["token"]

# Faire une prÃ©diction
files = {
    'image': ('document.jpg', open('path/to/your/document.jpg', 'rb'), 'image/jpeg')
}
headers = {
    "Authorization": f"Bearer {token}"
}
response = requests.post(
    "http://localhost:3000/predict",
    headers=headers,
    files=files
)
prediction = response.json()
print(prediction)
ğŸ“ˆ Monitoring
MÃ©triques disponibles

Performance du modÃ¨le (accuracy, prÃ©cision, recall)
Temps d'infÃ©rence
Utilisation des ressources (CPU, RAM, GPU)
DÃ©tection de drift
SantÃ© des services

Dashboards Grafana
Des dashboards prÃ©configurÃ©s sont disponibles pour :

Monitoring systÃ¨me
Performances du modÃ¨le
Analyse du drift
MÃ©triques d'API

ğŸ§ª Tests
bashCopy# Lancer les tests unitaires
pytest tests/

# Lancer les tests d'intÃ©gration
pytest tests/integration/

# VÃ©rifier la couverture des tests
pytest --cov=src tests/
ğŸ“ Documentation
La documentation complÃ¨te est disponible dans le dossier docs/ et inclut :

Guide d'installation dÃ©taillÃ©
Documentation API
Guide de contribution
SpÃ©cifications techniques

ğŸ¤ Contribution
Les contributions sont les bienvenues ! Consultez notre guide de contribution pour plus de dÃ©tails.
ğŸ‘¥ Ã‰quipe

Kevin Ory - LinkedIn
Xavier Truong - LinkedIn

ğŸ“„ Licence
Ce projet est sous licence MIT - voir le fichier LICENSE.md pour plus de dÃ©tails.
ğŸ™ Remerciements

DataScientest pour leur soutien et leur encadrement
La communautÃ© ML pour les ressources et outils open source
Les contributeurs du dataset RVL-CDIP

ğŸ“ Support
Pour toute question ou problÃ¨me :

Ouvrez une issue sur GitHub
Contactez l'Ã©quipe via LinkedIn
